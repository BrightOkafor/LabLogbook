{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAXZw-BOklA-"
   },
   "source": [
    "\n",
    "\n",
    "# RNN for Time Series\n",
    "\n",
    "RNNs are used for sequence modeling. This tutorial will look at a time series data to be modeled and predicted using RNNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WO9ntPgRklBA"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6HAjQBuklBA"
   },
   "source": [
    "## Data\n",
    "\n",
    "We will use retail data for time-series modeling. \n",
    "\n",
    "Link to the dataset:\n",
    " https://fred.stlouisfed.org/series/MRTSSM448USN\n",
    "\n",
    "Information about the Advance Monthly Retail Sales Survey can be found on the Census website at:\n",
    "https://www.census.gov/retail/marts/about_the_surveys.html\n",
    "\n",
    "Release: Advance Monthly Sales for Retail and Food Services  \n",
    "Units:  Millions of Dollars, Not Seasonally Adjusted\n",
    "Frequency:  Monthly\n",
    "\n",
    "Suggested Citation:\n",
    "U.S. Census Bureau, Advance Retail Sales: Clothing and Clothing Accessory Stores [RSCCASN], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/RSCCASN, November 16, 2019.\n",
    "\n",
    "https://fred.stlouisfed.org/series/RSCCASN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0afncMwmJiA"
   },
   "source": [
    "### Read data first -  Use index_col = 'DATE' and 'parse_dates = True' as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PWy0RE0iklBB"
   },
   "outputs": [],
   "source": [
    "# Your code to read data\n",
    "\n",
    "# Print first few rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20ILbN0TmrOJ"
   },
   "source": [
    "Does the sales column has any name?\n",
    "\n",
    "If no, set the name of the colum as 'Sales'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PZIxSODNklBC"
   },
   "outputs": [],
   "source": [
    "# Set name of column as 'Sales'. Use - df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcaD8pEsssHE"
   },
   "source": [
    "Plot your data - Year vs Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E_SQ6sB0klBC"
   },
   "outputs": [],
   "source": [
    "# Your code to plot Year vs Sales. Use either matplot library of pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYHObQ6lklBC"
   },
   "source": [
    "### Next we will do Train Test Split. \n",
    "\n",
    "We will use last 1.5 year (18 month) samples for testing. Rest is for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PljjHLVKklBD"
   },
   "outputs": [],
   "source": [
    "# Assign variable test size = 18\n",
    "# Store length of data in variable length.\n",
    "# store training size in varialable train_size (Remember training size = total size - test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlCkBwGOvV5z"
   },
   "source": [
    "Now, we will find the indexes of the test data. Remember, these are the last 18 indexes in the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ty_G_Ky8klBD"
   },
   "outputs": [],
   "source": [
    "#Assign the start of test index in data frame to variable test_index.  Remember, it is equal to the length of dataframe - test size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zzf2MiW0wcIP"
   },
   "source": [
    "Next, we will separate train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HyuEFcxoklBD"
   },
   "outputs": [],
   "source": [
    "# Store all data from 0 to test_index in variable train. Hint - Use df.iloc.\n",
    "# Store everthing from test_index to the last sample in test variable. Hint - Use df.iloc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a9-JOcqTklBE"
   },
   "outputs": [],
   "source": [
    "# Print the size of the train data\n",
    "# Print the size of the test data\n",
    "# Print the train data\n",
    "# Print the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnHYQqjTklBE"
   },
   "source": [
    "### In Neural Networks, we need to Scale Data between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TlhbNUf6klBE"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-yAHwjS3klBE"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m----> 2\u001b[0m scaler\u001b[38;5;241m.\u001b[39mfit(train)\n\u001b[1;32m      3\u001b[0m scaled_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(train)\n\u001b[1;32m      4\u001b[0m scaled_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "scaled_train = scaler.transform(train)\n",
    "scaled_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr7DoWM2klBE"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Check if the data has been scaled properly\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkRDFTCnklBE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzvXEF_8klBE"
   },
   "source": [
    "# Time Series Generator\n",
    "\n",
    "This class takes in a sequence of data-points gathered at\n",
    "equal intervals, along with time series parameters such as\n",
    "stride, length of history, etc., to produce batches for\n",
    "training/validation.\n",
    "\n",
    "#### Arguments\n",
    "    data: Indexable generator (such as list or Numpy array)\n",
    "        containing consecutive data points (timesteps).\n",
    "        The data should be at 2D, and axis 0 is expected\n",
    "        to be the time dimension.\n",
    "    targets: Targets corresponding to timesteps in `data`.\n",
    "        It should have same length as `data`.\n",
    "    length: Length of the output sequences (in number of timesteps).\n",
    "    sampling_rate: Period between successive individual timesteps\n",
    "        within sequences. For rate `r`, timesteps\n",
    "        `data[i]`, `data[i-r]`, ... `data[i - length]`\n",
    "        are used for create a sample sequence.\n",
    "    stride: Period between successive output sequences.\n",
    "        For stride `s`, consecutive output samples would\n",
    "        be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n",
    "    start_index: Data points earlier than `start_index` will not be used\n",
    "        in the output sequences. This is useful to reserve part of the\n",
    "        data for test or validation.\n",
    "    end_index: Data points later than `end_index` will not be used\n",
    "        in the output sequences. This is useful to reserve part of the\n",
    "        data for test or validation.\n",
    "    shuffle: Whether to shuffle output samples,\n",
    "        or instead draw them in chronological order.\n",
    "    reverse: Boolean: if `true`, timesteps in each output sample will be\n",
    "        in reverse chronological order.\n",
    "    batch_size: Number of timeseries samples in each batch\n",
    "        (except maybe the last one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ww3rFMDyeU6"
   },
   "source": [
    "# We will use 12 months as input and then predict the next month out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWGudaCKklBF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "length = 12\n",
    "generator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFkYAa_ZklBF"
   },
   "outputs": [],
   "source": [
    "X, y = generator[0]\n",
    "\n",
    "print(f'Given the Array: \\n{X.flatten()}')\n",
    "print(f'Predict this y: \\n {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2JNn76vklBF"
   },
   "source": [
    "### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8EKHpwsklBF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_e-ciXHklBF"
   },
   "outputs": [],
   "source": [
    "# We're only using one feature in our time series\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlstmafY1SJC"
   },
   "source": [
    "# Define your own models. \n",
    "\n",
    "Use 1. SimpleRNN, LSTM, or GRU neural network.\n",
    "\n",
    "APIs:\n",
    "https://keras.io/api/layers/recurrent_layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97CMSHdnklBF"
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Your code to create your own model\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uv4_LwBsklBF"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEySSjnXklBF"
   },
   "source": [
    "### EarlyStopping and creating a Validation Generator\n",
    "\n",
    "NOTE: The scaled_test dataset size MUST be greater than your length chosen for your batches. Review video for more info on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSOF0UdQklBG"
   },
   "outputs": [],
   "source": [
    "validation_generator = TimeseriesGenerator(scaled_test, scaled_test, length=length, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGXOa7vH2SGs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Your code to create an object early-stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGQ6FmGA2k3l"
   },
   "source": [
    "Now, fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3M9SdOWklBG"
   },
   "outputs": [],
   "source": [
    "# Your code to fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_FT924EklBG"
   },
   "outputs": [],
   "source": [
    "# Get Losses from dataframe (hint - model.history.history)- See previous week tutorial.\n",
    "# Plot losses in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLHR70OiklBG"
   },
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfBvM-PDklBG"
   },
   "outputs": [],
   "source": [
    "first_eval_batch = scaled_train[-length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilrLhGP5klBG"
   },
   "outputs": [],
   "source": [
    "n_input = 12\n",
    "first_eval_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "model.predict(first_eval_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with the true result:\n",
    "scaled_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKjgr2QtklBH"
   },
   "source": [
    "#### Try predicting the series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cem82lC7klBH"
   },
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "first_eval_batch = scaled_train[-length:]\n",
    "current_batch = first_eval_batch.reshape((1, length, n_features))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    \n",
    "    # get prediction 1 time stamp ahead ([0] is for \n",
    "    # grabbing just the number instead of [array])\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # store prediction\n",
    "    test_predictions.append(current_pred) \n",
    "    \n",
    "    # update batch to now include prediction and drop first value\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2400W3cklBH"
   },
   "source": [
    "## Inverse Transformations and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CTT2EJWklBH"
   },
   "outputs": [],
   "source": [
    "true_predictions = scaler.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkQkA0HXklBH"
   },
   "outputs": [],
   "source": [
    "# IGNORE WARNINGS\n",
    "test['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbrJUx7z3hQF"
   },
   "source": [
    "# Check and plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SovbmFX1klBH"
   },
   "outputs": [],
   "source": [
    "# Print the test variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GI2daeyCklBH"
   },
   "outputs": [],
   "source": [
    "# Your code to plot actual sales and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "m-G9Sj8QklBH"
   },
   "source": [
    "# Retrain and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_LWNZcsklBH"
   },
   "outputs": [],
   "source": [
    "full_scaler = MinMaxScaler()\n",
    "scaled_full_data = full_scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Bv8HMGUklBH"
   },
   "outputs": [],
   "source": [
    "length = 12 # Length of the output sequences (in number of timesteps)\n",
    "generator = TimeseriesGenerator(scaled_full_data, \n",
    "                                scaled_full_data, length=length, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rur4U6DqklBH"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Use any neural network model based on RNN\n",
    "#\n",
    "# Create the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLRI3xk6klBH"
   },
   "outputs": [],
   "source": [
    "forecast = []\n",
    "# Replace periods with whatever forecast length you want\n",
    "periods = 12\n",
    "\n",
    "first_eval_batch = scaled_full_data[-length:]\n",
    "current_batch = first_eval_batch.reshape((1, length, n_features))\n",
    "\n",
    "for i in range(periods):\n",
    "    \n",
    "    # get prediction 1 time stamp ahead ([0] is for  grabbing just the number instead of [array])\n",
    "    \n",
    "    \n",
    "    # store prediction forecast.append(current_pred) \n",
    "    \n",
    "    # update batch to now include prediction and drop first value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrOvllWLklBI"
   },
   "outputs": [],
   "source": [
    "forecast = scaler.inverse_transform(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SX2a204lklBI"
   },
   "source": [
    "### Creating new timestamp index with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKFbxg4nklBI"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXqTleSCklBI"
   },
   "outputs": [],
   "source": [
    "forecast_index = pd.date_range(start='2024-01-01',periods=periods,freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0M8HAJ2BklBI"
   },
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(data=forecast,index=forecast_index,\n",
    "                           columns=['Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgbJpcIAklBI"
   },
   "outputs": [],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXkkIIBjklBI"
   },
   "outputs": [],
   "source": [
    "# Plot sales - Values in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wVB2DQM5ovH"
   },
   "outputs": [],
   "source": [
    "# Plot forecast - Values in forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjgZ7bnMklBI"
   },
   "source": [
    "### Joining pandas plots\n",
    "\n",
    "https://stackoverflow.com/questions/13872533/plot-different-dataframes-in-the-same-figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SimiIvlQklBI",
    "outputId": "3b363ed7-3bf7-4bc9-8131-25e35dd754a6"
   },
   "outputs": [],
   "source": [
    "ax = df.plot()\n",
    "forecast_df.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPJKP6sMklBI",
    "outputId": "a9ca203b-d289-47e2-9532-a077148ebd0b"
   },
   "outputs": [],
   "source": [
    "ax = df.plot()\n",
    "forecast_df.plot(ax=ax)\n",
    "plt.xlim('2022-01-01','2025-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UncpiS4klBI"
   },
   "source": [
    "# Try the same example with a LSTM and GRU! \n",
    "Hint: Use LSTM instead of SimpleRNN!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
